{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import TypedDict\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nsrr_data.datamodule.stage_datamodule import SleepStageDataset\n",
    "from nsrr_data.datamodule.transforms.stft_transform import STFTTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define collate fn to collect elements in a batchx\n",
    "def collate_fn(batch) -> TypedDict:\n",
    "\n",
    "    subject_id_map = [x[\"record\"].split(\"_\")[0] for x in batch]\n",
    "    waveforms = torch.stack([torch.as_tensor(x[\"signal\"]) for x in batch]).to(torch.float32)\n",
    "    targets = torch.stack([torch.as_tensor(x[\"stages\"]) for x in batch])\n",
    "    global_information = subject_id_map\n",
    "\n",
    "    N, L, C, F, T = waveforms.shape\n",
    "    if L == 1:\n",
    "        waveforms = waveforms.squeeze(1)\n",
    "    else:\n",
    "        waveforms = rearrange(waveforms, \"N L C T -> N C (L T)\")\n",
    "\n",
    "    return dict(waveform=waveforms, global_information=global_information, targets=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cache for data prep: /home/aneol/waveform-conversion/notebooks/data/.cache\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[08/07/23 23:43:46] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Prefetching study metadata using <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1</span> workers:                       <a href=\"file:///dtu-compute/macaroni/toolboxes/nsrr-data/nsrr_data/datamodule/stage_dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">stage_dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///dtu-compute/macaroni/toolboxes/nsrr-data/nsrr_data/datamodule/stage_dataset.py#66\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">66</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[08/07/23 23:43:46]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Prefetching study metadata using \u001b[1;36m-1\u001b[0m workers:                       \u001b]8;id=387828;file:///dtu-compute/macaroni/toolboxes/nsrr-data/nsrr_data/datamodule/stage_dataset.py\u001b\\\u001b[2mstage_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=134210;file:///dtu-compute/macaroni/toolboxes/nsrr-data/nsrr_data/datamodule/stage_dataset.py#66\u001b\\\u001b[2m66\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 8950.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Prefetching finished                                               <a href=\"file:///dtu-compute/macaroni/toolboxes/nsrr-data/nsrr_data/datamodule/stage_dataset.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">stage_dataset.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///dtu-compute/macaroni/toolboxes/nsrr-data/nsrr_data/datamodule/stage_dataset.py#71\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">71</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Prefetching finished                                               \u001b]8;id=879883;file:///dtu-compute/macaroni/toolboxes/nsrr-data/nsrr_data/datamodule/stage_dataset.py\u001b\\\u001b[2mstage_dataset.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=568295;file:///dtu-compute/macaroni/toolboxes/nsrr-data/nsrr_data/datamodule/stage_dataset.py#71\u001b\\\u001b[2m71\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate sleep stage object\n",
    "records = sorted(list(Path('/home/aneol/waveform-conversion/data/processed/shhs').rglob('*.h5')))[:10]\n",
    "ds = SleepStageDataset(\n",
    "    records=records,\n",
    "    sequence_length=1,\n",
    "    cache_data=True,\n",
    "    fs=128,\n",
    "    n_jobs=-1,\n",
    "    picks=['c4'],\n",
    "    scaling='standard',\n",
    "    transform=STFTTransform(\n",
    "        fs=128,\n",
    "        segment_size=128,\n",
    "        step_size=16,\n",
    "        nfft=128\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8836/8836 [00:21<00:00, 411.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the dataset and collect outputs\n",
    "batch = []\n",
    "for idx, el in enumerate(tqdm(ds)):\n",
    "    batch.append(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally grab everything in one batch\n",
    "batch = collate_fn(batch=batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wavecon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
